{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6de89c87",
   "metadata": {},
   "source": [
    "# Design document\n",
    "\n",
    "## Adversarial estimation on graphs \n",
    "For ground truth dataset graph dataset $G = (X,Y,N,A) $ where:\n",
    "- X is a matrix of $n \\times k$ exogenous characteristics of individual nodes, i.e. each node is asociated with $k$ dimensinal vector of features\n",
    "- Y is a matrix of $n \\times l$ endogenous outcomes of individual nodes, i.e. each node is asociated with $k$ dimensinal vector of outcomes\n",
    "- N = \\{0,...,n\\} is set of node indicises\n",
    "- A $n\\times n$ is and adjacency matrix, symmetric and $A \\in \\{0,1\\}^{n\\times n}$\n",
    "\n",
    "Structural model $m_{\\theta}: R^{n \\times k } \\to R^{n \\times l }$, $m$ is parametrized by uknown vector $\\theta$.\n",
    "\n",
    "Synthetic dataset $G(\\theta)' = (X,Y',N,A) $ where $Y'=m_{\\theta}(X,A, \\theta)$\n",
    "\n",
    "GNN discriminator $D: g_i \\to [0,1]$, $g_i$ is a graph.\n",
    "\n",
    "We search for $\\theta*$ such that:\n",
    "$$ \\theta* \\in \\arg \\min_{\\theta} \\max_{D} L(G'(\\theta),G)$$\n",
    "\n",
    "where the loss $L$ is some classification quality metric we want to minimize (e.g. accuracy).\n",
    "\n",
    "### Algorithm description \n",
    "In general use ego sampling centered around randomly selected node idices with neigbourhood of size h=1.\n",
    "\n",
    "repeat until convergence of $\\theta$:\n",
    "  - sample ground truth data from $G$ \n",
    "  - for fixed $\\theta$ use $m_{\\theta}$ to generate synthetic data $G'=(X,Y',N,A)$\n",
    "  - sample synthetic data from $G'$\n",
    "  - create labeled dataset where subgraps drawn from $G$ have label 0 and synthetic examples form $G'$ have label 1\n",
    "  - make train test split \n",
    "  - train GNN discriminator $D$\n",
    "  - evaluate performance on a test set \n",
    "\n",
    "\n",
    "## Repository structure\n",
    "\n",
    "   \\structural_gnn_lib\n",
    "\n",
    "   \\\\ estimator\n",
    "  \n",
    "  \\\\\\ __init__.py\n",
    "\n",
    "  \\\\\\ estimator.py\n",
    "\n",
    "  \\\\ generator\n",
    "  \n",
    "  \\\\\\ __init__.py\n",
    "\n",
    "  \\\\\\ generator.py\n",
    "\n",
    "  \\\\ utils\n",
    "\n",
    "  \\\\\\ __init__.py\n",
    "\n",
    "  \\\\\\ utils.py\n",
    "\n",
    "\\linear_in_means.ipynb\n",
    "\n",
    "## tools to use\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from skopt import gp_minimize\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## Required objects\n",
    "\n",
    "Following sections describe specifications of objects required to implement above described algorithm. The demands are very concrete.\n",
    "\n",
    "## test dataset\n",
    "example of creating test dataset\n",
    "        self.num_nodes = num_nodes\n",
    "        self.true_a = true_a\n",
    "        self.true_b = true_b\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "        # Generate a fixed random graph using the Erdos-RÃ©nyi model\n",
    "        self.G = nx.erdos_renyi_graph(n=num_nodes, p=p, seed=seed)\n",
    "        self.adjacency = nx.adjacency_matrix(self.G).todense()\n",
    "        \n",
    "        # Generate univariate node features\n",
    "        self.x = np.random.randn(num_nodes, 1)\n",
    "        \n",
    "        # Generate outcomes y based on neighbors' x values\n",
    "        self.y = np.zeros((num_nodes, 1))\n",
    "        for i in range(num_nodes):\n",
    "            neighbors = list(self.G.neighbors(i))\n",
    "            if neighbors:\n",
    "                mean_neighbor_x = np.mean(self.x[neighbors])\n",
    "            else:\n",
    "                mean_neighbor_x = 0.0\n",
    "            self.y[i] = true_a + true_b * mean_neighbor_x\n",
    "\n",
    "## Generator class\n",
    "\n",
    "### class GeneratorBase:\n",
    "\n",
    "This class defines abstract properties of generator classes, general purpose \n",
    "of the simulator is to supply data to the adversarial estimator, this class abstracts behaviour\n",
    "of two child classes:\n",
    "\n",
    "1) GroundTruthGenerator\n",
    "    - is instantiated from ground truth data, graph $G = \\{X,Y,A,N\\}$, where $X$ is matrix containing exogenous covariates for each node ($n \\times k$),  $Y$ is a matrix containing node level outcomes,  $A$ is symmetric adjacency matrix (undirected graph, $n \\times n$) and $N = \\{1,...,n\\}$ is a collection of node indices. The data necessary for a creation of ground truth generator instance are supplied externally and are assumed to be wrangled into correct format.\n",
    "\n",
    "2) SyntheticGenerator\n",
    "- intherits exogenous data from the GroundTruthGenerator instance\n",
    "  i.e. from $G = \\{X,Y,A,N\\}$,  ${X,A,N\\}$ are inherited as immutable data members of the SyntheticGenerator class instance. In addition  GroundTruthGenerator needs a structural_model function which will take ${X,A,N\\}$ and generates synthetic outcomes $Y'$. \n",
    "\n",
    "  For example for linear in means model the structural_model function is: \n",
    "  y_i = a + b * mean(x_j) for j in neighbors(i)\n",
    "\n",
    "  \n",
    "All generator classes implement indentical sample_subgraphs method:\n",
    "\n",
    "   def sample_subgraphs(self, node_ids):\n",
    "        \"\"\"\n",
    "        Extract induced subgraphs centered on specified nodes.\n",
    "        \n",
    "        For each node in node_ids, creates a subgraph containing the node and all\n",
    "        its neighbors, with features and outcomes preserved from the original graph.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        node_ids : list\n",
    "            List of node indices to sample subgraphs from\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        list\n",
    "            List of PyTorch Geometric Data objects representing subgraphs\n",
    "        \"\"\"\n",
    "\n",
    "example of sampling \n",
    "\n",
    "   subgraphs = []\n",
    "        for node in node_ids:\n",
    "            # Ensure the subgraph contains the target node and its neighbors\n",
    "            nodes = [node] + list(self.G.neighbors(node))\n",
    "            subgraph = self.G.subgraph(nodes).copy()\n",
    "            \n",
    "            # Relabel nodes for internal consistency\n",
    "            mapping = {n: i for i, n in enumerate(nodes)}\n",
    "            subgraph = nx.relabel_nodes(subgraph, mapping)\n",
    "            \n",
    "            # Retrieve features and outcomes from the ground truth\n",
    "            x_sub = torch.tensor(self.x[nodes], dtype=torch.float)\n",
    "            y_sub = torch.tensor(self.y[nodes], dtype=torch.float)\n",
    "            \n",
    "            # Combine x and y into a single feature vector per node\n",
    "            features = torch.cat([x_sub, y_sub], dim=1)\n",
    "            \n",
    "            # Build edge index (ensuring both directions for an undirected graph)\n",
    "            edge_index = torch.tensor(list(subgraph.edges), dtype=torch.long).t().contiguous()\n",
    "            if edge_index.numel() > 0:\n",
    "                edge_index = torch.cat([edge_index, edge_index[[1, 0], :]], dim=1)\n",
    "            else:\n",
    "                edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "                \n",
    "            # Create PyTorch Geometric Data object\n",
    "            data = Data(x=features, edge_index=edge_index, \n",
    "                        original_nodes=nodes,  # Store original node IDs for visualization\n",
    "                        original_graph=subgraph)  # Store NetworkX graph for visualization\n",
    "            subgraphs.append(data)\n",
    "        return subgraphs\n",
    "            \n",
    "The Synthetic generator class has generate_outcomes(self, theta) which generates outcomes for fixed $X,A,N$ and variable parameter vector $\\theta$\n",
    "\n",
    "\n",
    "## GraphDiscriminator(torch.nn.Module)\n",
    "\n",
    "Is a graph neural network whose purpose is to discriminate between sythetic and ground truth data.\n",
    "\n",
    "Is initialized with: \n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        \"\"\"\n",
    "        Initialize the GNN discriminator.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_dim : int\n",
    "            Dimension of input node features\n",
    "        hidden_dim : int\n",
    "            Dimension of hidden node representations\n",
    "        num_classes : int\n",
    "            Number of output classes (2 for binary classification)\n",
    "        \"\"\"\n",
    "\n",
    "And has a formard(self, data) methods as ususal torch NN\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Forward pass through the GNN.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : torch_geometric.data.Data\n",
    "            Input graph data\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        torch.Tensor\n",
    "            Logits for each class\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "## Utility functions\n",
    "\n",
    "- defined in utils subdirectory\n",
    "\n",
    "### create_dateset\n",
    "\n",
    "Factory function which will combine ground truth subgraphs sampled from a ground truth generator using and synthetic data from synthetic data generator instance to a labeled dataset, before train test split.\n",
    "\n",
    "def create_dataset(real_subgraphs, synthetic_subgraphs):\n",
    "    \"\"\"\n",
    "    Create a dataset combining real and synthetic subgraphs with class labels.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    real_subgraphs : list\n",
    "        List of PyTorch Geometric Data objects from the ground truth\n",
    "    synthetic_subgraphs : list\n",
    "        List of PyTorch Geometric Data objects from the synthetic simulator\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        Combined dataset with class labels (0 for real, 1 for synthetic)\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    for data in real_subgraphs:\n",
    "        data.label = torch.tensor(0, dtype=torch.long)\n",
    "        dataset.append(data)\n",
    "    for data in synthetic_subgraphs:\n",
    "        data.label = torch.tensor(1, dtype=torch.long)\n",
    "        dataset.append(data)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "### evaluate_discriminator\n",
    "\n",
    "Helper function to evaluate discriminator on a test set. \n",
    "\n",
    "def evaluate_discriminator(model, loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate the discriminator model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : GraphDiscriminator\n",
    "        The GNN discriminator model\n",
    "    loader : torch_geometric.data.DataLoader\n",
    "        DataLoader containing evaluation data\n",
    "    device : torch.device\n",
    "        Device to run computations on\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Classification accuracy\n",
    "    \"\"\"\n",
    "\n",
    "### objective_function\n",
    "\n",
    "Objective function for outside loop optimization task. Wraps around\n",
    "ground truth generator, synthetic generator, discriminator and manages whole synthetic data generation process, returns value of discriminator accuracy on test set to be minimized.\n",
    "\n",
    "def objective_function(theta, ground_truth_generator, m, num_epochs=20, verbose=False):\n",
    "    \"\"\"\n",
    "    Objective function for parameter estimation.\n",
    "    \n",
    "    For candidate parameters theta, generates synthetic outcomes, trains a GNN \n",
    "    discriminator to distinguish between real and synthetic data, and returns\n",
    "    the test accuracy (which we want to minimize).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    theta : list or numpy.ndarray\n",
    "        Candidate parameters theta\n",
    "    ground_truth_simulator : GroundTruthGenerator\n",
    "        The ground truth generator\n",
    "    m : int\n",
    "        Number of nodes to sample for subgraphs\n",
    "    num_epochs : int\n",
    "        Number of epochs to train the discriminator\n",
    "    verbose : bool\n",
    "        Whether to print progress information\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Test accuracy of the discriminator (objective to minimize)\n",
    "    \"\"\"\n",
    "\n",
    "## AdversarialEstimator \n",
    "\n",
    "Takes advantage of the described utility and helper functions to run the adversarial estimation. Using gp_minimize from scikit optimize. Has a constructor that takes in ground truth data, initial params vector and potentially optimizer.\n",
    "Within constructor the estimator will build the objective function using proposed utils and classes and run the estimation.\n",
    "\n",
    "defaul optimizer setting\n",
    "result = gp_minimize(\n",
    "        safe_objective,\n",
    "        space,\n",
    "        n_calls=500,                # Total evaluations - reduce this for testing\n",
    "        n_initial_points=400,       # Initial random evaluations\n",
    "        noise=0.2,                  # Explicitly model noise\n",
    "        acq_func='EI',              #  Expected Improvement acquisition function\n",
    "        callback=gp_callback,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,                  # Set to 1 for debugging, -1 for production\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "## misc functions \n",
    "\n",
    "Additional function outside of the library meant specifically for visualistation\n",
    "of test two parameter linear in means model minimization objective as 2d surface.\n",
    "Is used within the test notebook. \n",
    "\n",
    "def visualize_objective_surface(estimator, m, resolution=20, num_epochs=5, verbose=False):\n",
    "    \"\"\"\n",
    "    Visualize the objective function as a 2D surface.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    estimator:\n",
    "\n",
    "    m : int\n",
    "        Number of nodes to sample for each evaluation\n",
    "    device : torch.device\n",
    "        Device to run computations on\n",
    "    resolution : int\n",
    "        Resolution of the grid for parameter values\n",
    "    num_epochs : int\n",
    "        Number of epochs to train the discriminator for each evaluation\n",
    "    verbose : bool\n",
    "        Whether to print progress information\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53b0084",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
