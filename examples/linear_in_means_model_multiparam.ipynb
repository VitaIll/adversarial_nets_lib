{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"An issue occurred while importing 'torch-sparse'\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"An issue occurred while importing 'torch-cluster'\")\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "from adversarial_nets import AdversarialEstimator, GraphDataset\n",
    "\n",
    "\n",
    "def build_peer_operator(A: np.ndarray, row_normalize: bool = True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Make a peer operator P from adjacency A with zero diagonal.\n",
    "    Optionally row-normalize by degree; isolates pure peer effects and avoids self-loops.\n",
    "    \"\"\"\n",
    "    P = A.copy().astype(float)\n",
    "    np.fill_diagonal(P, 0.0)\n",
    "    if row_normalize:\n",
    "        deg = P.sum(axis=1, keepdims=True)\n",
    "        # Safe normalization: rows with zero degree remain zeros\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            P = np.divide(P, deg, out=np.zeros_like(P), where=(deg > 0))\n",
    "    return P\n",
    "\n",
    "def simulate_linear_in_means(X: np.ndarray,\n",
    "                             A: np.ndarray,\n",
    "                             theta: np.ndarray,\n",
    "                             noise_std: float = 0.1) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Ground-truth simulator: y = (I - rho P)^{-1} (alpha*1 + beta*X + gamma*P X + eps)\n",
    "    X: (n, 1) single scalar feature per node (for simplicity)\n",
    "    A: (n, n) adjacency\n",
    "    theta: [alpha, beta, gamma, rho]\n",
    "    \"\"\"\n",
    "    alpha, beta, gamma, rho = map(float, theta)\n",
    "    n = X.shape[0]\n",
    "    P = build_peer_operator(A, row_normalize=True)\n",
    "    I = np.eye(n)\n",
    "\n",
    "    # Right-hand side: alpha*1 + beta*x + gamma*P*x + eps\n",
    "    rhs = alpha * np.ones(n) + beta * X[:, 0] + gamma * (P @ X[:, 0]) + np.random.normal(0.0, noise_std, size=n)\n",
    "\n",
    "    # Solve (I - rho P) y = rhs\n",
    "    y = np.linalg.solve(I - rho * P, rhs)\n",
    "    return y\n",
    "\n",
    "def structural_model(x: np.ndarray, adjacency: np.ndarray, y0: np.ndarray, theta: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Structural mapping required by AdversarialEstimator.\n",
    "    Ignores y0 here (kept for API compatibility).\n",
    "    \"\"\"\n",
    "    # x expected (n, k). We assume k=1 for simplicity; if k>1, use x[:,0] or adapt the formula.\n",
    "    return simulate_linear_in_means(x[:, [0]], adjacency, theta, noise_std=0.0)\n",
    "\n",
    "def discriminator_factory(input_dim: int, hidden_dim: int = 32, num_classes: int = 1) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Very small GNN discriminator: one GCN layer, mean pool, linear head.\n",
    "    \"\"\"\n",
    "    class SimpleGNN(nn.Module):\n",
    "        def __init__(self, in_dim, hid_dim, out_dim):\n",
    "            super().__init__()\n",
    "            self.conv = GCNConv(in_dim, hid_dim)\n",
    "            self.classifier = nn.Linear(hid_dim, out_dim)\n",
    "\n",
    "        def forward(self, x, edge_index, batch):\n",
    "            x = F.relu(self.conv(x, edge_index))\n",
    "            x = F.dropout(x, p=0.2, training=self.training)\n",
    "            x = global_mean_pool(x, batch)\n",
    "            return self.classifier(x)  # BCEWithLogitsLoss inside estimator\n",
    "\n",
    "    return SimpleGNN(input_dim, hidden_dim, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "def create_test_graph_dataset(n_nodes: int = 150,\n",
    "                              p_edge: float = 0.05,\n",
    "                              theta_true = (0.7, 1.2, 0.8, 0.3),\n",
    "                              seed: int = 42) -> GraphDataset:\n",
    "    \"\"\"\n",
    "    Make a toy graph with one exogenous feature per node and outcomes y from the true theta.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    G = nx.erdos_renyi_graph(n_nodes, p_edge, seed=seed)\n",
    "    A = nx.to_numpy_array(G, dtype=float)\n",
    "\n",
    "    # One scalar feature per node\n",
    "    X = rng.normal(0.0, 1.0, size=(n_nodes, 1))\n",
    "\n",
    "    # Ensure safe rho (optional; true theta already chosen benignly)\n",
    "    P = build_peer_operator(A, row_normalize=True)\n",
    "    eigvals = np.linalg.eigvals(P)\n",
    "    lambda_max = float(np.max(np.abs(eigvals))) if eigvals.size else 0.0\n",
    "    if lambda_max > 0 and abs(theta_true[3]) >= 0.99 / lambda_max:\n",
    "        rho_safe = 0.8 / lambda_max\n",
    "        theta_true = (theta_true[0], theta_true[1], theta_true[2], rho_safe)\n",
    "\n",
    "    Y = simulate_linear_in_means(X, A, np.array(theta_true), noise_std=0.1)\n",
    "    N = list(range(n_nodes))\n",
    "    return GraphDataset(X=X, Y=Y, A=A, N=N)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # True structural parameters: (alpha, beta, gamma, rho)\n",
    "    TRUE_THETA = (0.7, 1.2, 0.8, 0.3)\n",
    "\n",
    "    # 1) Data\n",
    "    data = create_test_graph_dataset(n_nodes=180, p_edge=0.06, theta_true=TRUE_THETA, seed=123)\n",
    "\n",
    "    # 2) Bounds: loose for (alpha, beta, gamma); rho constrained by spectral radius of P\n",
    "    P = build_peer_operator(data.A, row_normalize=True)\n",
    "    eigvals = np.linalg.eigvals(P)\n",
    "    lam_max = float(np.max(np.abs(eigvals))) if eigvals.size else 1.0\n",
    "    rho_cap = (0.99 / lam_max) if lam_max > 0 else 0.99  # |rho| < 1 / lambda_max\n",
    "    bounds = [(-5.0, 5.0), (-5.0, 5.0), (-5.0, 5.0), (-rho_cap, rho_cap)]\n",
    "\n",
    "    # 3) Estimator (small settings; bump up for real runs)\n",
    "    estimator = AdversarialEstimator(\n",
    "        ground_truth_data=data,\n",
    "        structural_model=structural_model,\n",
    "        initial_params=[0.0, 0.0, 0.0, 0.0],\n",
    "        bounds=bounds,\n",
    "        discriminator_factory=discriminator_factory,\n",
    "        gp_params=dict(\n",
    "            initial_point_generator=\"sobol\",\n",
    "            n_initial_points=64,\n",
    "            noise=0.10,\n",
    "        ),\n",
    "        # You can also pass sampler options here if your API exposes them.\n",
    "    )\n",
    "\n",
    "    # 4) Estimate\n",
    "    # m = subgraphs per objective eval; num_epochs = discriminator training per eval\n",
    "    result = estimator.estimate(m=128, num_epochs=8, verbose=True)\n",
    "    theta_hat = result[\"x\"] if isinstance(result, dict) else result.x\n",
    "\n",
    "    # 5) Report\n",
    "    names = [\"alpha\", \"beta\", \"gamma\", \"rho\"]\n",
    "    print(\"\\n=== Estimated parameters (linear-in-means, 4 params) ===\")\n",
    "    for nm, t, th in zip(names, TRUE_THETA, theta_hat):\n",
    "        print(f\"{nm:>6s}: true = {t: .4f},  est = {th: .4f},  abs.err = {abs(th - t): .4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
