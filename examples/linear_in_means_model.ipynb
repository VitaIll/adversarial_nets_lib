{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Linear in means model\n",
    "\n",
    "Following notebook runs a test of structural adversarial estimation of linear in means peer effect model of a form:\n",
    "$$ y_i = a + b \\cdot  1/|\\mathcal{N(i)}| \\sum_{j \\in \\mathcal{N(i)}} x_j + \\varepsilon_i$$\n",
    "\n",
    "Where $y_i$ is a scalar outcome of node $i$, $\\mathcal{N(i)}$ is set of $i$'s neighbours and $x_j$ is some characteristic of $j$ exogenous to the structural model.\n",
    "Ultimately, such model can be easily estimated with cross-sectional OLS but this experiment shows that our method works for trivial case, and for 2 parameter model we are able to visualize objective and optimization path. The discriminator is simple GNN with a single convolutional layer and linear classifier and we use ego sampling of depth 1 to create the training sample. Outside minimization problem of the adversarial objective is solved with surrogate optimization using GP as model of expected improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"An issue occurred while importing 'torch-sparse'\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"An issue occurred while importing 'torch-cluster'\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from adversarial_nets import (\n",
    "    AdversarialEstimator,\n",
    "    GraphDataset,\n",
    "    objective_function\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NODES = 2500\n",
    "N_SAMPLES = 2000\n",
    "N_EPOCHS = 6\n",
    "RESOLUTION = 10\n",
    "P = 0.01\n",
    "\n",
    "def create_test_graph_dataset(\n",
    "    num_nodes: int = 100,\n",
    "    true_a: float = 1.0,\n",
    "    true_b: float = 2.0,\n",
    "    p: float = 0.01,\n",
    "    seed: int = 42\n",
    ") -> GraphDataset:\n",
    "    \"\"\"Generate a test graph dataset for a linear-in-means model.\"\"\"\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    G = nx.erdos_renyi_graph(n=num_nodes, p=p, seed=seed)\n",
    "    A = nx.adjacency_matrix(G).todense()  \n",
    "    X = np.random.randn(num_nodes, 1)\n",
    "\n",
    "    Y = np.zeros((num_nodes, 1))\n",
    "    for i in range(num_nodes):\n",
    "        neighbors = list(G.neighbors(i))\n",
    "        if neighbors:\n",
    "            mean_neighbor_x = np.mean(X[neighbors], axis=0)\n",
    "        else:\n",
    "            mean_neighbor_x = 0.0\n",
    "        Y[i] = true_a + true_b * mean_neighbor_x + np.random.normal(0.0, 0.1)\n",
    "\n",
    "    N = list(range(num_nodes))\n",
    "\n",
    "    return GraphDataset(X=X, Y=Y, A=A, N=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Structural model mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit, prange\n",
    "\n",
    "@njit(parallel=True)\n",
    "def linear_in_means_model(x, adjacency, theta):\n",
    "    \"\"\"\n",
    "    Numba-optimized linear-in-means model with automatic parallelization.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x : numpy.ndarray\n",
    "        Node features (n × k) - must be C-contiguous\n",
    "    adjacency : numpy.ndarray\n",
    "        Adjacency matrix (n × n) - must be C-contiguous\n",
    "    theta : tuple or list\n",
    "        Parameters (a, b) - pass as tuple for better Numba performance\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Generated outcomes (n × 1)\n",
    "    \"\"\"\n",
    "    a, b = theta[0], theta[1]\n",
    "    n = x.shape[0]\n",
    "    y = np.zeros((n, 1), dtype=x.dtype)\n",
    "    \n",
    "    for i in prange(n):\n",
    "        neighbor_sum = 0.0\n",
    "        neighbor_count = 0\n",
    "        \n",
    "        for j in range(n):\n",
    "            if adjacency[i, j] > 0:\n",
    "                neighbor_sum += x[j, 0]\n",
    "                neighbor_count += 1\n",
    "        \n",
    "        if neighbor_count > 0:\n",
    "            mean_neighbor_x = neighbor_sum / neighbor_count\n",
    "        else:\n",
    "            mean_neighbor_x = 0.0\n",
    "            \n",
    "        y[i, 0] = a + b * mean_neighbor_x\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_factory(input_dim, hidden_dim=16, num_classes=2):\n",
    "    class SimpleGNN(nn.Module):\n",
    "        def __init__(self, in_dim, hid_dim, num_cls):\n",
    "            super().__init__()\n",
    "            self.conv = GCNConv(in_dim, hid_dim)\n",
    "            self.classifier = nn.Linear(hid_dim, num_cls)\n",
    "\n",
    "        def forward(self, data):\n",
    "            x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "            x = F.relu(self.conv(x, edge_index))\n",
    "            x = F.dropout(x, p=0.2, training=self.training)\n",
    "            x = global_mean_pool(x, batch)\n",
    "            return self.classifier(x)\n",
    "\n",
    "    return SimpleGNN(input_dim, hidden_dim, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Visualization utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_objective_surface(estimator, m, resolution, num_epochs, verbose=False):\n",
    "    a_range = np.linspace(-3, 5, resolution)\n",
    "    b_range = np.linspace(-1, 5, resolution)\n",
    "    A, B = np.meshgrid(a_range, b_range)\n",
    "\n",
    "    Z = np.zeros_like(A)\n",
    "\n",
    "    total_evals = resolution * resolution\n",
    "    with tqdm(total=total_evals, desc=\"Evaluating objective surface\") as pbar:\n",
    "        for i in range(resolution):\n",
    "            for j in range(resolution):\n",
    "                theta = [A[i, j], B[i, j]]\n",
    "                Z[i, j] = objective_function(\n",
    "                    theta,\n",
    "                    estimator.ground_truth_generator,\n",
    "                    estimator.synthetic_generator,\n",
    "                    discriminator_factory=estimator.discriminator_factory,\n",
    "                    num_epochs=num_epochs,\n",
    "                    m=m,\n",
    "                    verbose=verbose,\n",
    "                )\n",
    "                pbar.update(1)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    surf = ax1.plot_surface(A, B, Z, cmap='viridis', alpha=0.8)\n",
    "    ax1.set_xlabel('Parameter a')\n",
    "    ax1.set_ylabel('Parameter b')\n",
    "    ax1.set_zlabel('Discriminator Accuracy')\n",
    "    ax1.set_title('Objective Function Surface')\n",
    "\n",
    "    true_a, true_b = 1.0, 2.0\n",
    "    ax1.scatter([true_a], [true_b], [Z.min()], color='red', s=100, marker='*', label='True params')\n",
    "\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    contour = ax2.contour(A, B, Z, levels=20, cmap='viridis')\n",
    "    ax2.clabel(contour, inline=True, fontsize=8)\n",
    "    ax2.scatter([true_a], [true_b], color='red', s=100, marker='*', label='True params')\n",
    "\n",
    "    if hasattr(estimator, 'estimated_params') and estimator.estimated_params is not None:\n",
    "        est_a, est_b = estimator.estimated_params\n",
    "        ax1.scatter([est_a], [est_b], [Z.min()], color='orange', s=100, marker='^', label='Estimated params')\n",
    "        ax2.scatter([est_a], [est_b], color='orange', s=100, marker='^', label='Estimated params')\n",
    "\n",
    "    ax2.set_xlabel('Parameter a')\n",
    "    ax2.set_ylabel('Parameter b')\n",
    "    ax2.set_title('Objective Function Contours')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.colorbar(surf, ax=ax1, shrink=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return Z, (A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"Testing Adversarial Estimation for Linear-in-Means Model\")\n",
    "    print(\"=\" * 60)\n",
    "    true_params = [1.0, 2.0]\n",
    "    print(\"\\n1. Generating test dataset...\")\n",
    "    test_data = create_test_graph_dataset(num_nodes=N_NODES, true_a=true_params[0], true_b=true_params[1], p=P)\n",
    "\n",
    "    print(\"\\n2. Creating adversarial estimator...\")\n",
    "    estimator = AdversarialEstimator(\n",
    "        ground_truth_data=test_data,\n",
    "        structural_model=linear_in_means_model,\n",
    "        initial_params=[0.0, 0.0],\n",
    "        bounds=[(-10, 10), (-10, 10)],\n",
    "        discriminator_factory=discriminator_factory\n",
    "    )\n",
    "\n",
    "    print(\"\\n3. Visualizing objective function surface...\")\n",
    "\n",
    "    visualize_objective_surface(\n",
    "        estimator,\n",
    "        m=N_SAMPLES,\n",
    "        resolution=RESOLUTION,\n",
    "        num_epochs=N_EPOCHS,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "\n",
    "    print(\"\\n4. Running adversarial estimation...\")\n",
    "    result = estimator.estimate(m=N_SAMPLES, num_epochs=N_EPOCHS, verbose=True)\n",
    "    estimated_params = result['x'] if isinstance(result, dict) else result.x\n",
    "    estimator.estimated_params = estimated_params\n",
    "\n",
    "    print(\"\\n5. Results:\")\n",
    "    print(f\"   - True parameters: a={true_params[0]}, b={true_params[1]}\")\n",
    "    print(f\"   - Estimated parameters: a={estimated_params[0]:.4f}, b={estimated_params[1]:.4f}\")\n",
    "    print(\n",
    "        f\"   - Estimation error: a_error={abs(estimated_params[0] - true_params[0]):.4f}, \"\n",
    "        f\"b_error={abs(estimated_params[1] - true_params[1]):.4f}\"\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
